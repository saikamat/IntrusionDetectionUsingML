{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Author: Kumar Awanish,\n",
    "    Content: Implementation of multiclass classification on complete data(Approach C)\n",
    "        Technology used: Python3, Pandas, Spark, Tsne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkContext\n",
    "from pyspark import SparkConf\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import  StringIndexer, VectorAssembler, IndexToString\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.context import SparkContext\n",
    "from pyspark.serializers import MarshalSerializer\n",
    "import time\n",
    "import numpy as np\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import roc_curve, auc, roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import f1_score\n",
    "from pyspark.ml.feature import VectorIndexer\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark import SparkContext\n",
    "from pyspark.sql import SQLContext\n",
    "import pandas as pd\n",
    "import os\n",
    "from pyspark.ml.regression import RandomForestRegressor\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting Spark enviroment "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "memory = '100g'\n",
    "pyspark_submit_args = ' --driver-memory ' + memory + ' pyspark-shell'\n",
    "os.environ[\"PYSPARK_SUBMIT_ARGS\"] = pyspark_submit_args\n",
    "SparkContext.setSystemProperty('spark.executor.memory', '80g')\n",
    "#SparkContext.setSystemProperty('spark.driver.memory', '10g')\n",
    "sc = SparkContext('local','example')  # if using locally\n",
    "sql_sc = SQLContext(sc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data loading and change type to float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_loading(dataset):\n",
    "    \"\"\"\n",
    "    This function will load dataset using Spark cluster.\n",
    "    :param dataset: dataset to load and process\n",
    "    :return: a Spark dataframe\n",
    "    \"\"\"\n",
    "    dataset=sql_sc.read.format('csv').options(header='true', inferSchema='true').load(dataset)\n",
    "    # #changing column header name\n",
    "    dataset = dataset.select(*[col(s).alias('Label') if s == ' Label' else s for s in dataset.columns])\n",
    "    #to change datatype\n",
    "    dataset=dataset.drop('External IP')\n",
    "    dataset = dataset.filter(dataset.Label.isNotNull())\n",
    "    dataset=dataset.filter(dataset.Label!=' Label')#filter Label from label\n",
    "    print(dataset.groupBy('Label').count().collect())\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_preprocessing(dataset):\n",
    "    \"\"\"\n",
    "    This function is for preprocessing of datasets.\n",
    "    :param dataset: a spark dataframe\n",
    "    :return finalRegressionData: a spark dataframe after preprocessing \n",
    "    \"\"\"\n",
    "    featureList=[' Flow Duration', ' Fwd IAT Min', ' Bwd IAT Mean', ' Fwd IAT Mean','Init_Win_bytes_forward',' Subflow Fwd Bytes','Total Length of Fwd Packets',\n",
    "      ' ACK Flag Count', ' Active Min', 'Active Mean',' Flow IAT Std','Init_Win_bytes_forward','Fwd PSH Flags',' SYN Flag Count',\n",
    "      'Fwd Packets/s',' Bwd Packet Length Std','Total Length of Fwd Packets','Init_Win_bytes_forward',' Init_Win_bytes_backward','Total Length of Fwd Packets',\n",
    "      'Total Length of Fwd Packets','Active Mean','Total Length of Fwd Packets',' Fwd Packet Length Mean',' Average Packet Size','Init_Win_bytes_forward', ' Bwd Packets/s', ' PSH Flag Count', ' Flow IAT Min', ' Fwd IAT Min', ' Flow IAT Mean']\n",
    "\n",
    "    uniqueFeature=list(set(featureList))\n",
    "    uniqueFeature.append('Label')\n",
    "    #data set for regression\n",
    "    dataForRegression=dataset.select([c for c in dataset.columns if c in uniqueFeature])\n",
    "    #from pyspark.ml.feature import StringIndexer\n",
    "    indexer = StringIndexer(inputCol=\"Label\", outputCol=\"categoryIndex\")\n",
    "    indexed = indexer.fit(dataForRegression).transform(dataForRegression)\n",
    "    print(\"StringIndexer will store labels in output column metadata\\n\")\n",
    "\n",
    "    converter = IndexToString(inputCol=\"categoryIndex\", outputCol=\"originalCategory\")\n",
    "    converted = converter.transform(indexed)\n",
    "\n",
    "    print(\"Transformed indexed column '%s' back to original string column '%s' using \"\n",
    "          \"labels in metadata\" % (converter.getInputCol(), converter.getOutputCol()))\n",
    "    converted.select(\"Label\", \"categoryIndex\", \"originalCategory\").show(5)\n",
    "    #check encoding and decoding\n",
    "    print(converted.groupBy('categoryIndex','originalCategory').count().collect())\n",
    "    dataRegression=indexed.drop('Label')\n",
    "    #to change datatype\n",
    "    finalRegressionData=dataRegression.select(*(col(c).cast(\"float\").alias(c) for c in dataRegression.columns))\n",
    "    #finalRegressionData.cache()\n",
    "    finalRegressionData = finalRegressionData.filter(finalRegressionData.categoryIndex.isNotNull())\n",
    "    finalRegressionData = finalRegressionData.na.fill(0.0)\n",
    "    print(finalRegressionData.groupBy('categoryIndex').count().collect())\n",
    "    return finalRegressionData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorAssembler(finalRegressionData):\n",
    "    \"\"\"\n",
    "    This function is for creating feature indexer, which will be helpful in running RF model on PySpark Api.\n",
    "    :param finalRegressionData: preprocessed spark dataframe\n",
    "    :return finalRegressionData: spark dataframe with feature indexer column added to it\n",
    "    \"\"\"\n",
    "    stages = [] # stages in our Pipeline\n",
    "    assemblerInputs=finalRegressionData.columns[0:-1]\n",
    "    assembler = VectorAssembler(inputCols=assemblerInputs, outputCol=\"features\")\n",
    "    #assembler.transform(final_data)\n",
    "    assembler.transform(finalRegressionData.na.drop())\n",
    "    stages += [assembler]\n",
    "    cols = finalRegressionData.columns\n",
    "    # Create a Pipeline.\n",
    "    pipeline = Pipeline(stages=stages)\n",
    "    # Run the feature transformations.\n",
    "    #  - fit() computes feature statistics as needed.\n",
    "    #  - transform() actually transforms the features.\n",
    "    pipelineModel = pipeline.fit(finalRegressionData)\n",
    "    finalRegressionData = pipelineModel.transform(finalRegressionData)\n",
    "    # Keep relevant columns\n",
    "    selectedcols = [\"features\"] + cols\n",
    "    finalRegressionData = finalRegressionData.select(selectedcols)\n",
    "    return finalRegressionData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def results_For_RegrAttacks(finalRegressionDataFromAssembler):\n",
    "    \"\"\"\n",
    "    This method output model accuracy and its results\n",
    "    :param finalRegressionDataFromAssembler:  preprocessed spark dataframe\n",
    "    :return trainingData, testData: test and train data\n",
    "    \"\"\"\n",
    "    # Split the data into training and test sets (30% held out for testing)\n",
    "    (trainingData, testData) = finalRegressionDataFromAssembler.randomSplit([0.85, 0.15])\n",
    "    model=RandomForestRegressor(featuresCol=\"features\",labelCol=\"categoryIndex\",maxDepth=10,numTrees=100)\n",
    "    #,numTrees=100,maxDepth=20\n",
    "    time_start = time.time()\n",
    "    rf=model.fit(trainingData)\n",
    "    print ('Training time for RF Regressor: {} seconds'.format(time.time()-time_start))\n",
    "#     rf.write().overwrite().save('mdoelTrainedApproachC')\n",
    "    rf.save('mdoelTrainedApproachC')\n",
    "    predictions=rf.transform(testData)\n",
    "    # Select (prediction, true label) and compute test error\n",
    "#     evaluator = RegressionEvaluator(\n",
    "#         labelCol=\"categoryIndex\", predictionCol=\"prediction\", metricName=\"rmse\")\n",
    "#     rmse = evaluator.evaluate(predictions)\n",
    "#     print(\"Root Mean Squared Error (RMSE) on test data = %g\" % rmse)\n",
    "    outputrf=np.array(predictions.select('prediction').collect())\n",
    "    input_array=np.array(testData.select('categoryIndex').collect())\n",
    "#     print(\"Precision Score for RF model=%g\"%(precision_score(input_array, outputrf.round(), average='macro')))\n",
    "#     print(\"Recall Score for RF model=%g\"%(recall_score(input_array, outputrf.round(), average='macro') )) \n",
    "    print(\"F1 ->macro Score for RF model=%g\"%(f1_score(input_array, outputrf.round(), average='macro')))\n",
    "    print(\"Accuracy ->macro Score for RF model=%g\"%(accuracy_score(input_array, outputrf.round())))\n",
    "    print(\"Benign vs Attack result\")\n",
    "    print(classification_report(input_array, outputrf.round()))\n",
    "    return trainingData, testData, rf,outputrf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualisation using Tsne "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from sklearn.manifold import TSNE\n",
    "def tsneTrain(testData):\n",
    "    datavisualisation=testData.toPandas()\n",
    "    datavisualisation.drop(['features', ' SYN Flag Count', ' PSH Flag Count',' ACK Flag Count','Fwd PSH Flags'],axis=1,inplace=True)\n",
    "    time_start = time.time()\n",
    "    tsne = TSNE(n_components=2, verbose=1, perplexity=50)\n",
    "    tsne_resultsRf = tsne.fit_transform(datavisualisation[:80000])\n",
    "    print ('t-SNE done! Time elapsed: {} seconds'.format(time.time()-time_start))\n",
    "    return tsne_resultsRf\n",
    "%matplotlib inline\n",
    "def plot(tsne_resultsRfPred,labelss):\n",
    "    target_ids = range(0,15)\n",
    "    #target_ids = range(0,2)\n",
    "    font_size = 10\n",
    "    from matplotlib import pyplot as plt\n",
    "    #plt.figure(figsize=(6, 5))\n",
    "    plt.figure(figsize=(10,10))\n",
    "    colors = 'r', 'g', 'b', 'c', 'm', 'y', 'k', 'orange', 'purple','dimgray','rosybrown','firebrick','maroon','khaki','indigo'\n",
    "    #colors = 'r', 'g'\n",
    "    for i, c, label in zip(target_ids, colors, [_ for _ in target_ids]):\n",
    "        plt.scatter(tsne_resultsRfPred[labelss==i, 0], tsne_resultsRfPred[labelss==i, 1], c=c, label=label,s=1.5)\n",
    "    plt.title(\"Predcited Data Distribution on complete data by applying RF regressor \", fontsize=font_size,loc=\"center\")\n",
    "    plt.xlabel(\"Dimension 1\", fontsize=font_size)\n",
    "    plt.ylabel(\"Dimension 2\", fontsize=font_size)\n",
    "    plt.legend(loc=1,fontsize =font_size,bbox_to_anchor=(1.05, 1,), borderaxespad=-3.3)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Steps to train and run Approach C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Row(Label='BENIGN', count=1869700), Row(Label='SSH-Patator', count=5034), Row(Label='Web Attack � Brute Force', count=1507), Row(Label='Infiltration', count=36), Row(Label='Web Attack � Sql Injection', count=21), Row(Label='PortScan', count=158930), Row(Label='Bot', count=1966), Row(Label='���', count=1), Row(Label='DDoS', count=41835), Row(Label='FTP-Patator', count=7938), Row(Label='Web Attack � XSS', count=652)]\n",
      "StringIndexer will store labels in output column metadata\n",
      "\n",
      "Transformed indexed column 'categoryIndex' back to original string column 'originalCategory' using labels in metadata\n",
      "+------+-------------+----------------+\n",
      "| Label|categoryIndex|originalCategory|\n",
      "+------+-------------+----------------+\n",
      "|BENIGN|          0.0|          BENIGN|\n",
      "|BENIGN|          0.0|          BENIGN|\n",
      "|BENIGN|          0.0|          BENIGN|\n",
      "|BENIGN|          0.0|          BENIGN|\n",
      "|BENIGN|          0.0|          BENIGN|\n",
      "+------+-------------+----------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "[Row(categoryIndex=2.0, originalCategory='DDoS', count=41835), Row(categoryIndex=10.0, originalCategory='���', count=1), Row(categoryIndex=5.0, originalCategory='Bot', count=1966), Row(categoryIndex=9.0, originalCategory='Web Attack � Sql Injection', count=21), Row(categoryIndex=1.0, originalCategory='PortScan', count=158930), Row(categoryIndex=6.0, originalCategory='Web Attack � Brute Force', count=1507), Row(categoryIndex=8.0, originalCategory='Infiltration', count=36), Row(categoryIndex=4.0, originalCategory='SSH-Patator', count=5034), Row(categoryIndex=0.0, originalCategory='BENIGN', count=1869700), Row(categoryIndex=7.0, originalCategory='Web Attack � XSS', count=652), Row(categoryIndex=3.0, originalCategory='FTP-Patator', count=7938)]\n",
      "[Row(categoryIndex=9.0, count=21), Row(categoryIndex=5.0, count=1966), Row(categoryIndex=7.0, count=652), Row(categoryIndex=2.0, count=41835), Row(categoryIndex=3.0, count=7938), Row(categoryIndex=10.0, count=1), Row(categoryIndex=1.0, count=158930), Row(categoryIndex=6.0, count=1507), Row(categoryIndex=8.0, count=36), Row(categoryIndex=4.0, count=5034), Row(categoryIndex=0.0, count=1869700)]\n"
     ]
    }
   ],
   "source": [
    "#Step1: load data\n",
    "dataset=data_loading(\"/home/developer/Documents/kamat_MA/ids_with_rbfn/dataset/final.csv\")\n",
    "\n",
    "#Step2: preprocess data\n",
    "finalRegressionData=data_preprocessing(dataset)\n",
    "\n",
    "#Step3: vector assembler\n",
    "finalRegressionDataFromAssembler=vectorAssembler(finalRegressionData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time for RF Regressor: 860.9832677841187 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/developer/.local/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/developer/.local/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 ->macro Score for RF model=0.431906\n",
      "Accuracy ->macro Score for RF model=0.955183\n",
      "Benign vs Attack result\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.97      0.98    280648\n",
      "         1.0       0.67      1.00      0.80     23921\n",
      "         2.0       0.53      0.12      0.20      6335\n",
      "         3.0       0.97      0.98      0.98      1233\n",
      "         4.0       0.78      0.50      0.61       744\n",
      "         5.0       0.00      0.00      0.00       289\n",
      "         6.0       0.73      0.77      0.75       252\n",
      "         7.0       0.00      0.00      0.00        87\n",
      "         8.0       0.00      0.00      0.00         7\n",
      "         9.0       0.00      0.00      0.00         5\n",
      "\n",
      "   micro avg       0.96      0.96      0.96    313521\n",
      "   macro avg       0.47      0.44      0.43    313521\n",
      "weighted avg       0.96      0.96      0.95    313521\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Step4: model evaluation and results\n",
    "trainingData, testData,rf,outputrf=results_For_RegrAttacks(finalRegressionDataFromAssembler)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualisation using Tsne on test data for true and predicted labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train tsne \n",
    "tsne_resultsRf=tsneTrain(testData)\n",
    "\n",
    "#flatted to covert from(x,1) to (x,)\n",
    "predctedLable=outputrf.round().flatten()\n",
    "#plot tsne for predictedLabel\n",
    "plot(tsne_resultsRf,predctedLable[:80000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "truelabel=input_array.flatten()\n",
    "#plot tsne for predictedLabel\n",
    "plot(tsne_resultsRf,truelabel[:80000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "print(\"Accuracy ->macro Score for RF model=%g\"%(accuracy_score(input_array, outputrf.round(), average='macro')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
